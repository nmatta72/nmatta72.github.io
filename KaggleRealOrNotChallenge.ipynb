{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC, NuSVC\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, cross_validate\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.util import ngrams\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from nltk.stem.porter import *\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk import ngrams\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define useful functions\n",
    "def train_model(X,y, model, show_figures=True): \n",
    "    y_pred = cross_val_predict(model, X, y, cv=5)\n",
    "    score = f1_score(y,y_pred)\n",
    "    print(\"F1 Score = {0:.4f}\".format(score))\n",
    "    if show_figures:\n",
    "        model.fit(X, y)\n",
    "    return model, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the data\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will start off by looking at the text variable only\n",
    "X_train = train[['text', 'target', 'id']].copy()\n",
    "y_train = np.array(train['target']) #convert to an array for model\n",
    "X_test = test[['text', 'id']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Models - Before Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my first attempt at a model, I would like to see the performance of a few simple models before cleaning the data. By understanding the performance of these models, I will understand the impact of my data cleaning steps. I will also try two tokenizers - CountVectorizer and TFIDF, to see which one performs better. I have disregarded the `keyword` variable in this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  id\n",
       "0  Our Deeds are the Reason of this #earthquake M...       1   1\n",
       "1             Forest fire near La Ronge Sask. Canada       1   4\n",
       "2  All residents asked to 'shelter in place' are ...       1   5\n",
       "3  13,000 people receive #wildfires evacuation or...       1   6\n",
       "4  Just got sent this photo from Ruby #Alaska as ...       1   7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X_train_vect = vectorizer.fit_transform(X_train['text'].values)\n",
    "X_test_vect = vectorizer.transform(X_test['text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_model = MultinomialNB()\n",
    "NB_model.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score = 0.6753\n"
     ]
    }
   ],
   "source": [
    "NB_fitted_model, score = train_model(X_train_vect, y_train, NB_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselines_df = pd.DataFrame(columns=['Baseline Model', 'F1 Score'])\n",
    "baselines_df.loc[len(baselines_df)] = ['Baseline NB - CountVectorizer', round(score,4)]\n",
    "baselines_df\n",
    "\n",
    "results_df = pd.DataFrame(columns=['NB Model - Cleaning Steps', 'F1 Score'])\n",
    "results_df.loc[len(results_df)] = ['Baseline NB', round(score,4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vect = vectorizer.fit_transform(X_train['text'].values)\n",
    "X_test_vect = vectorizer.transform(X_test['text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score = 0.6445\n"
     ]
    }
   ],
   "source": [
    "NB_fitted_model, score = train_model(X_train_vect, y_train, NB_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline Model</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Baseline NB - CountVectorizer</td>\n",
       "      <td>0.6753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Baseline NB - TFIDF</td>\n",
       "      <td>0.6445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Baseline Model  F1 Score\n",
       "0  Baseline NB - CountVectorizer    0.6753\n",
       "1            Baseline NB - TFIDF    0.6445"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baselines_df.loc[len(baselines_df)] = ['Baseline NB - TFIDF', round(score,4)]\n",
    "baselines_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X_train_vect = vectorizer.fit_transform(X_train['text'].values)\n",
    "X_test_vect = vectorizer.transform(X_test['text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = LinearSVC()\n",
    "svm.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score = 0.5985\n"
     ]
    }
   ],
   "source": [
    "svm_fitted_model, score = train_model(X_train_vect, y_train, svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline Model</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Baseline NB - CountVectorizer</td>\n",
       "      <td>0.6753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Baseline NB - TFIDF</td>\n",
       "      <td>0.6445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Baseline SVM - CV</td>\n",
       "      <td>0.5985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Baseline Model  F1 Score\n",
       "0  Baseline NB - CountVectorizer    0.6753\n",
       "1            Baseline NB - TFIDF    0.6445\n",
       "2              Baseline SVM - CV    0.5985"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baselines_df.loc[len(baselines_df)] = ['Baseline SVM - CV', round(score,4)]\n",
    "baselines_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vect = vectorizer.fit_transform(X_train['text'].values)\n",
    "X_test_vect = vectorizer.transform(X_test['text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score = 0.6215\n"
     ]
    }
   ],
   "source": [
    "svm_fitted_model, score = train_model(X_train_vect, y_train, svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline Model</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Baseline NB - CountVectorizer</td>\n",
       "      <td>0.6753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Baseline NB - TFIDF</td>\n",
       "      <td>0.6445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Baseline SVM - CV</td>\n",
       "      <td>0.5985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Baseline SVM - TFIDF</td>\n",
       "      <td>0.6215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Baseline Model  F1 Score\n",
       "0  Baseline NB - CountVectorizer    0.6753\n",
       "1            Baseline NB - TFIDF    0.6445\n",
       "2              Baseline SVM - CV    0.5985\n",
       "3           Baseline SVM - TFIDF    0.6215"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baselines_df.loc[len(baselines_df)] = ['Baseline SVM - TFIDF', round(score,4)]\n",
    "baselines_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X_train_vect = vectorizer.fit_transform(X_train['text'].values)\n",
    "X_test_vect = vectorizer.transform(X_test['text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikit\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikit\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score = 0.6284\n"
     ]
    }
   ],
   "source": [
    "LogReg_fitted_model, score = train_model(X_train_vect, y_train, log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline Model</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Baseline NB - CountVectorizer</td>\n",
       "      <td>0.6753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Baseline NB - TFIDF</td>\n",
       "      <td>0.6445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Baseline SVM - CV</td>\n",
       "      <td>0.5985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Baseline SVM - TFIDF</td>\n",
       "      <td>0.6215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Baseline Log Reg - CV</td>\n",
       "      <td>0.6284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Baseline Model  F1 Score\n",
       "0  Baseline NB - CountVectorizer    0.6753\n",
       "1            Baseline NB - TFIDF    0.6445\n",
       "2              Baseline SVM - CV    0.5985\n",
       "3           Baseline SVM - TFIDF    0.6215\n",
       "4          Baseline Log Reg - CV    0.6284"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baselines_df.loc[len(baselines_df)] = ['Baseline Log Reg - CV', round(score,4)]\n",
    "baselines_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vect = vectorizer.fit_transform(X_train['text'].values)\n",
    "X_test_vect = vectorizer.transform(X_test['text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score = 0.6412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikit\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "LogReg_fitted_model, score = train_model(X_train_vect, y_train, log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline Model</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Baseline NB - CountVectorizer</td>\n",
       "      <td>0.6753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Baseline NB - TFIDF</td>\n",
       "      <td>0.6445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Baseline SVM - CV</td>\n",
       "      <td>0.5985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Baseline SVM - TFIDF</td>\n",
       "      <td>0.6215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Baseline Log Reg - CV</td>\n",
       "      <td>0.6284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Baseline Log Reg - TFIDF</td>\n",
       "      <td>0.6412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Baseline Model  F1 Score\n",
       "0  Baseline NB - CountVectorizer    0.6753\n",
       "1            Baseline NB - TFIDF    0.6445\n",
       "2              Baseline SVM - CV    0.5985\n",
       "3           Baseline SVM - TFIDF    0.6215\n",
       "4          Baseline Log Reg - CV    0.6284\n",
       "5       Baseline Log Reg - TFIDF    0.6412"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baselines_df.loc[len(baselines_df)] = ['Baseline Log Reg - TFIDF', round(score,4)]\n",
    "baselines_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes seems to be the best model for this dataset. Surprisingly, Count Vectorizer performs better than TF-IDF in the baseline model. This could be due to the fact that since there is a character limit on tweets, users are more likely to condense their message to important words and possibly skip out on stopwords that appear frequently. Additionally, since these are emergency tweets, there will be some common frequent words like alarm, panic, accident. Although these words may appear frequently, we do not want them dicounted by TF-IDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have an understanding of the baseline performance of these models, we will implement some cleaning steps to assess the impact on performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove punctuation\n",
    "X_train['text_cleaned'] = X_train['text'].str.replace(r'[^\\w\\s]+', '')\n",
    "X_test['text_cleaned'] = X_test['text'].str.replace(r'[^\\w\\s]+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>text_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Our Deeds are the Reason of this earthquake Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Forest fire near La Ronge Sask Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>All residents asked to shelter in place are be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>13000 people receive wildfires evacuation orde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>Just got sent this photo from Ruby Alaska as s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  id  \\\n",
       "0  Our Deeds are the Reason of this #earthquake M...       1   1   \n",
       "1             Forest fire near La Ronge Sask. Canada       1   4   \n",
       "2  All residents asked to 'shelter in place' are ...       1   5   \n",
       "3  13,000 people receive #wildfires evacuation or...       1   6   \n",
       "4  Just got sent this photo from Ruby #Alaska as ...       1   7   \n",
       "\n",
       "                                        text_cleaned  \n",
       "0  Our Deeds are the Reason of this earthquake Ma...  \n",
       "1              Forest fire near La Ronge Sask Canada  \n",
       "2  All residents asked to shelter in place are be...  \n",
       "3  13000 people receive wildfires evacuation orde...  \n",
       "4  Just got sent this photo from Ruby Alaska as s...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorize\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vect = vectorizer.fit_transform(X_train['text_cleaned'].values)\n",
    "X_test_vect = vectorizer.transform(X_test['text_cleaned'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apply model\n",
    "NB_model = MultinomialNB()\n",
    "NB_model.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score = 0.6708\n"
     ]
    }
   ],
   "source": [
    "NB_fitted_model, score = train_model(X_train_vect, y_train, NB_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NB Model - Cleaning Steps</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Baseline NB</td>\n",
       "      <td>0.6753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Punctuation Removed</td>\n",
       "      <td>0.6708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  NB Model - Cleaning Steps  F1 Score\n",
       "0               Baseline NB    0.6753\n",
       "1       Punctuation Removed    0.6708"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.loc[len(results_df)] = ['Punctuation Removed', round(score,4)]\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like punctuation removal is negatively impacting the performance of our model, however through many rounds of trial and error, I've noticed that combining the data cleaning is better for the model. Next I will remove digits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove digits\n",
    "X_train['text_cleaned'] = X_train['text_cleaned'].str.replace('\\d+', '')\n",
    "X_test['text_cleaned'] = X_test['text_cleaned'].str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorize again\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vect = vectorizer.fit_transform(X_train['text_cleaned'].values)\n",
    "X_test_vect = vectorizer.transform(X_test['text_cleaned'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apply simple model again\n",
    "NB_model = MultinomialNB()\n",
    "NB_model.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score = 0.6716\n"
     ]
    }
   ],
   "source": [
    "NB_fitted_model, score = train_model(X_train_vect, y_train, NB_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NB Model - Cleaning Steps</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Baseline NB</td>\n",
       "      <td>0.6753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Punctuation Removed</td>\n",
       "      <td>0.6708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Punct. &amp; Digits Removed</td>\n",
       "      <td>0.6716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  NB Model - Cleaning Steps  F1 Score\n",
       "0               Baseline NB    0.6753\n",
       "1       Punctuation Removed    0.6708\n",
       "2   Punct. & Digits Removed    0.6716"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.loc[len(results_df)] = ['Punct. & Digits Removed', round(score,4)]\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has slightly improved by removing digits from the text. In the case of tweets, removing digits is very important since many tweets contain locational and descriptive information that contain numbers. For example - \"An accident has been report on I-90\" or \"13,000 have died in...\". While important for a human, this information is meaningless for the model. Next I will remove stop words manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"text_cleaned_no_SW\"] = X_train[\"text_cleaned\"].str.split()\n",
    "X_test[\"text_cleaned_no_SW\"] = X_test[\"text_cleaned\"].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')\n",
    "X_train[\"text_cleaned_no_SW\"] = X_train[\"text_cleaned_no_SW\"].apply(lambda lst: [x for x in lst if x not in stop])\n",
    "X_test[\"text_cleaned_no_SW\"] = X_test[\"text_cleaned_no_SW\"].apply(lambda lst: [x for x in lst if x not in stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['text_cleaned_no_SW'] = X_train['text_cleaned_no_SW'].apply(' '.join)\n",
    "X_test['text_cleaned_no_SW'] = X_test['text_cleaned_no_SW'].apply(' '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X_train_vect = vectorizer.fit_transform(X_train['text_cleaned_no_SW'].values)\n",
    "X_test_vect = vectorizer.transform(X_test['text_cleaned_no_SW'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apply simple model again\n",
    "NB_model = MultinomialNB()\n",
    "NB_model.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score = 0.6614\n"
     ]
    }
   ],
   "source": [
    "NB_fitted_model, score = train_model(X_train_vect, y_train, NB_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NB Model - Cleaning Steps</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Baseline NB</td>\n",
       "      <td>0.6753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Punctuation Removed</td>\n",
       "      <td>0.6708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Punct. &amp; Digits Removed</td>\n",
       "      <td>0.6716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Punct, Digits &amp; SW Removed - manually</td>\n",
       "      <td>0.6614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               NB Model - Cleaning Steps  F1 Score\n",
       "0                            Baseline NB    0.6753\n",
       "1                    Punctuation Removed    0.6708\n",
       "2                Punct. & Digits Removed    0.6716\n",
       "3  Punct, Digits & SW Removed - manually    0.6614"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.loc[len(results_df)] = ['Punct, Digits & SW Removed - manually', round(score,4)]\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, the performance has decreased when removing stop words. We know that there must be some words in this document that are repeated frequently, however they might be different than the typical enlgish stopwords. I will assess the most common words in each class, that will give a good indication of what the stopwords could be in our case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify stopwords for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate the classes into different dataframes for further assessment\n",
    "X_train_0 = X_train[X_train['target'] == 0]\n",
    "X_train_1 = X_train[X_train['target'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate word frequencies for each class\n",
    "stopwords_0 = pd.Series(np.concatenate([x.split() for x in X_train_0['text_cleaned']])).value_counts()[:30].index.tolist()\n",
    "stopwords_1 = pd.Series(np.concatenate([x.split() for x in X_train_1['text_cleaned']])).value_counts()[:30].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'a', 'to', 'I', 'and', 'of', 'in', 'you', 'is', 'for', 'my', 'on', 'with', 'that', 'it', 'The', 'be', 'like', 'this', 'me', 'by', 'have', 'at', 'was', 'your', 'are', 'Im', 'just', 'amp', 'so']\n"
     ]
    }
   ],
   "source": [
    "print(stopwords_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'in', 'of', 'a', 'to', 'and', 'on', 'for', 'is', 'I', 'at', 'The', 'by', 'from', 'A', 'that', 'with', 'was', 'it', 'are', 'after', 'as', 'have', 'fire', 'via', 'this', 'over', 'you', 'California', 'amp']\n"
     ]
    }
   ],
   "source": [
    "print(stopwords_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that there is not much difference in the most frequent words that appear in both classes. Mostly all are stop words except for two words that appear in class 1: _via_ and _fire_. With this analysis, however, we are sure that there are not many frequent, meaningful words that will indicate the class of a tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results of all my cleaning steps, it may seem like the basic cleaning steps do not apply to this dataset, however after a few Kaggle submissions I've realized that these steps improve my model, although incrementally. When it comes to NLP analysis of tweets, text cleaning does not yield significant results most likely because there do not exist many punctuation marks, stopwords and other language nuances in tweets. This is probably due to the fact that tweets are subject to a 140 character limit, therefore users condense their messages. Upon analysis of the tweets, I've noticed that users usually share content in their tweets, which introduces a link starting with _http_. My next data cleaning step will be to remove links."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove http"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert string into list\n",
    "X_train['text_cleaned_no_SW'] = X_train['text_cleaned_no_SW'].apply(lambda x: x[0:-1].split())\n",
    "X_test['text_cleaned_no_SW'] = X_test['text_cleaned_no_SW'].apply(lambda x: x[0:-1].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove words starting with http\n",
    "X_train['text_cleaned_no_SW'] = X_train['text_cleaned_no_SW'].apply(lambda lst: [x for x in lst if not x.startswith(\"http\")])\n",
    "X_test['text_cleaned_no_SW'] = X_test['text_cleaned_no_SW'].apply(lambda lst: [x for x in lst if not x.startswith(\"http\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['text_cleaned_no_SW'] = X_train['text_cleaned_no_SW'].apply(' '.join).str.lower()\n",
    "X_test['text_cleaned_no_SW'] = X_test['text_cleaned_no_SW'].apply(' '.join).str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorize\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vect = vectorizer.fit_transform(X_train['text_cleaned_no_SW'].values)\n",
    "X_test_vect = vectorizer.transform(X_test['text_cleaned_no_SW'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apply simple model \n",
    "NB_model = MultinomialNB()\n",
    "NB_model.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score = 0.6675\n"
     ]
    }
   ],
   "source": [
    "nb_fitted_model, score = train_model(X_train_vect, y_train, NB_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NB Model - Cleaning Steps</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Baseline NB</td>\n",
       "      <td>0.6753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Punctuation Removed</td>\n",
       "      <td>0.6708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Punct. &amp; Digits Removed</td>\n",
       "      <td>0.6716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Punct, Digits &amp; SW Removed - manually</td>\n",
       "      <td>0.6614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Punct, Digits, SW &amp; Links Removed</td>\n",
       "      <td>0.6675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               NB Model - Cleaning Steps  F1 Score\n",
       "0                            Baseline NB    0.6753\n",
       "1                    Punctuation Removed    0.6708\n",
       "2                Punct. & Digits Removed    0.6716\n",
       "3  Punct, Digits & SW Removed - manually    0.6614\n",
       "4      Punct, Digits, SW & Links Removed    0.6675"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.loc[len(results_df)] = ['Punct, Digits, SW & Links Removed', round(score,4)]\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing links has slightly increased the performance of the model. As mentioned earlier, although these steps do not make much difference in the train set, these steps are very impactful in the test set. When working with the train set, it is important to note that case-specific data cleaning steps, such as removing words starting with 'http', generally will improve the model although the score may not indicate it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply stemming - Porter and Snowball Stemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Snowball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert string into list\n",
    "X_train['snowball_stemmed'] = X_train['text_cleaned_no_SW'].apply(lambda x: x[0:-1].split())\n",
    "X_test['snowball_stemmed'] = X_test['text_cleaned_no_SW'].apply(lambda x: x[0:-1].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "X_train['snowball_stemmed'] = X_train['snowball_stemmed'].apply(lambda lst: [stemmer.stem(x) for x in lst])\n",
    "X_test['snowball_stemmed'] = X_test['snowball_stemmed'].apply(lambda lst: [stemmer.stem(x) for x in lst])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['snowball_stemmed'] = X_train['snowball_stemmed'].apply(' '.join)\n",
    "X_test['snowball_stemmed'] = X_test['snowball_stemmed'].apply(' '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>text_cleaned_no_SW</th>\n",
       "      <th>snowball_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Our Deeds are the Reason of this earthquake Ma...</td>\n",
       "      <td>our deeds reason earthquake may allah forgive u</td>\n",
       "      <td>our deed reason earthquak may allah forgiv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Forest fire near La Ronge Sask Canada</td>\n",
       "      <td>forest fire near la ronge sask canad</td>\n",
       "      <td>forest fire near la rong sask cana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>All residents asked to shelter in place are be...</td>\n",
       "      <td>all residents asked shelter place notified off...</td>\n",
       "      <td>all resid ask shelter place notifi offic no ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>people receive wildfires evacuation orders in...</td>\n",
       "      <td>people receive wildfires evacuation orders cal...</td>\n",
       "      <td>peopl receiv wildfir evacu order californ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>Just got sent this photo from Ruby Alaska as s...</td>\n",
       "      <td>just got sent photo ruby alaska smoke wildfire...</td>\n",
       "      <td>just got sent photo rubi alaska smoke wildfir ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  id  \\\n",
       "0  Our Deeds are the Reason of this #earthquake M...       1   1   \n",
       "1             Forest fire near La Ronge Sask. Canada       1   4   \n",
       "2  All residents asked to 'shelter in place' are ...       1   5   \n",
       "3  13,000 people receive #wildfires evacuation or...       1   6   \n",
       "4  Just got sent this photo from Ruby #Alaska as ...       1   7   \n",
       "\n",
       "                                        text_cleaned  \\\n",
       "0  Our Deeds are the Reason of this earthquake Ma...   \n",
       "1              Forest fire near La Ronge Sask Canada   \n",
       "2  All residents asked to shelter in place are be...   \n",
       "3   people receive wildfires evacuation orders in...   \n",
       "4  Just got sent this photo from Ruby Alaska as s...   \n",
       "\n",
       "                                  text_cleaned_no_SW  \\\n",
       "0    our deeds reason earthquake may allah forgive u   \n",
       "1               forest fire near la ronge sask canad   \n",
       "2  all residents asked shelter place notified off...   \n",
       "3  people receive wildfires evacuation orders cal...   \n",
       "4  just got sent photo ruby alaska smoke wildfire...   \n",
       "\n",
       "                                    snowball_stemmed  \n",
       "0         our deed reason earthquak may allah forgiv  \n",
       "1                 forest fire near la rong sask cana  \n",
       "2  all resid ask shelter place notifi offic no ev...  \n",
       "3          peopl receiv wildfir evacu order californ  \n",
       "4  just got sent photo rubi alaska smoke wildfir ...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorize\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vect = vectorizer.fit_transform(X_train['snowball_stemmed'].values)\n",
    "X_test_vect = vectorizer.transform(X_test['snowball_stemmed'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_model = MultinomialNB()\n",
    "NB_model.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score = 0.6635\n"
     ]
    }
   ],
   "source": [
    "NB_fitted_model, score = train_model(X_train_vect, y_train, NB_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NB Model - Cleaning Steps</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Baseline NB</td>\n",
       "      <td>0.6753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Punctuation Removed</td>\n",
       "      <td>0.6708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Punct. &amp; Digits Removed</td>\n",
       "      <td>0.6716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Punct, Digits &amp; SW Removed - manually</td>\n",
       "      <td>0.6614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Punct, Digits, SW &amp; Links Removed</td>\n",
       "      <td>0.6675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Punct, Digits, SW &amp; Links Removed - Snowball</td>\n",
       "      <td>0.6635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      NB Model - Cleaning Steps  F1 Score\n",
       "0                                   Baseline NB    0.6753\n",
       "1                           Punctuation Removed    0.6708\n",
       "2                       Punct. & Digits Removed    0.6716\n",
       "3         Punct, Digits & SW Removed - manually    0.6614\n",
       "4             Punct, Digits, SW & Links Removed    0.6675\n",
       "5  Punct, Digits, SW & Links Removed - Snowball    0.6635"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.loc[len(results_df)] = ['Punct, Digits, SW & Links Removed - Snowball', round(score,4)]\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Porter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert string into list\n",
    "X_train['porter_stemmed'] = X_train['text_cleaned_no_SW'].apply(lambda x: x[0:-1].split())\n",
    "X_test['porter_stemmed'] = X_test['text_cleaned_no_SW'].apply(lambda x: x[0:-1].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "X_train['porter_stemmed'] = X_train['porter_stemmed'].apply(lambda lst: [stemmer.stem(x) for x in lst])\n",
    "X_test['porter_stemmed'] = X_test['porter_stemmed'].apply(lambda lst: [stemmer.stem(x) for x in lst])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['porter_stemmed'] = X_train['porter_stemmed'].apply(' '.join)\n",
    "X_test['porter_stemmed'] = X_test['porter_stemmed'].apply(' '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorize\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vect = vectorizer.fit_transform(X_train['porter_stemmed'].values)\n",
    "X_test_vect = vectorizer.transform(X_test['porter_stemmed'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_model = MultinomialNB()\n",
    "NB_model.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score = 0.6648\n"
     ]
    }
   ],
   "source": [
    "NB_fitted_model, score = train_model(X_train_vect, y_train, NB_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NB Model - Cleaning Steps</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Baseline NB</td>\n",
       "      <td>0.6753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Punctuation Removed</td>\n",
       "      <td>0.6708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Punct. &amp; Digits Removed</td>\n",
       "      <td>0.6716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Punct, Digits &amp; SW Removed - manually</td>\n",
       "      <td>0.6614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Punct, Digits, SW &amp; Links Removed</td>\n",
       "      <td>0.6675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Punct, Digits, SW &amp; Links Removed - Snowball</td>\n",
       "      <td>0.6635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Punct, Digits, SW &amp; Links Removed - Porter</td>\n",
       "      <td>0.6648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      NB Model - Cleaning Steps  F1 Score\n",
       "0                                   Baseline NB    0.6753\n",
       "1                           Punctuation Removed    0.6708\n",
       "2                       Punct. & Digits Removed    0.6716\n",
       "3         Punct, Digits & SW Removed - manually    0.6614\n",
       "4             Punct, Digits, SW & Links Removed    0.6675\n",
       "5  Punct, Digits, SW & Links Removed - Snowball    0.6635\n",
       "6    Punct, Digits, SW & Links Removed - Porter    0.6648"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.loc[len(results_df)] = ['Punct, Digits, SW & Links Removed - Porter', round(score,4)]\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that both forms of stemming decrease the performance of our model slightly. Let's see if lemmatization works better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "X_train['text_Lemmatized'] = X_train['text_cleaned_no_SW'].apply(lambda x: x[0:-1].split())\n",
    "X_test['text_Lemmatized'] = X_test['text_cleaned_no_SW'].apply(lambda x: x[0:-1].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['text_Lemmatized'] = X_train['text_Lemmatized'].apply(lambda lst: [lemmatizer.lemmatize(x, get_wordnet_pos(x)) for x in lst])\n",
    "X_test['text_Lemmatized'] = X_test['text_Lemmatized'].apply(lambda lst: [lemmatizer.lemmatize(x, get_wordnet_pos(x)) for x in lst])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['text_Lemmatized'] = X_train['text_Lemmatized'].apply(' '.join)\n",
    "X_test['text_Lemmatized'] = X_test['text_Lemmatized'].apply(' '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorize\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vect = vectorizer.fit_transform(X_train['text_Lemmatized'].values)\n",
    "X_test_vect = vectorizer.transform(X_test['text_Lemmatized'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_model = MultinomialNB()\n",
    "NB_model.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score = 0.6673\n"
     ]
    }
   ],
   "source": [
    "NB_fitted_model, score = train_model(X_train_vect, y_train, NB_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NB Model - Cleaning Steps</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Baseline NB</td>\n",
       "      <td>0.6753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Punctuation Removed</td>\n",
       "      <td>0.6708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Punct. &amp; Digits Removed</td>\n",
       "      <td>0.6716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Punct, Digits &amp; SW Removed - manually</td>\n",
       "      <td>0.6614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Punct, Digits, SW &amp; Links Removed</td>\n",
       "      <td>0.6675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Punct, Digits, SW &amp; Links Removed - Snowball</td>\n",
       "      <td>0.6635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Punct, Digits, SW &amp; Links Removed - Porter</td>\n",
       "      <td>0.6648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Punct, Digits, SW &amp; Links Removed - Lemmatized</td>\n",
       "      <td>0.6673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        NB Model - Cleaning Steps  F1 Score\n",
       "0                                     Baseline NB    0.6753\n",
       "1                             Punctuation Removed    0.6708\n",
       "2                         Punct. & Digits Removed    0.6716\n",
       "3           Punct, Digits & SW Removed - manually    0.6614\n",
       "4               Punct, Digits, SW & Links Removed    0.6675\n",
       "5    Punct, Digits, SW & Links Removed - Snowball    0.6635\n",
       "6      Punct, Digits, SW & Links Removed - Porter    0.6648\n",
       "7  Punct, Digits, SW & Links Removed - Lemmatized    0.6673"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.loc[len(results_df)] = ['Punct, Digits, SW & Links Removed - Lemmatized', round(score,4)]\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization seems to be a better approach than stemming, most likely because with lemmatization, the meaning of the word isn't lost. For example, in the snowball stemmer, the word \"residents\" turned into \"resid\" which has no meanind the English language. With lemmatization, on the other hand, \"residents\" would turn into \"resident\", which has the same meaning and it is more easily recognized by the model. Next I will apply bigrams to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply ngrams - create a column of bigrams for assessment, apply ngram_range parameter in vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #convert string into list\n",
    "# X_train['bigrams'] = X_train['text_cleaned'].apply(lambda x: x[0:-1].split())\n",
    "# X_test['bigrams'] = X_test['text_cleaned'].apply(lambda x: x[0:-1].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #create a new column for bigrams\n",
    "# X_train['bigrams'] = X_train['bigrams'].apply(lambda row: list(ngrams(row, 2)))\n",
    "# X_test['bigrams'] = X_test['bigrams'].apply(lambda row: list(ngrams(row, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train['bigrams'] = X_train['bigrams'].apply(', '.join)\n",
    "# X_test['bigrams'] = X_test['bigrams'].apply(', '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorize\n",
    "vectorizer = CountVectorizer(ngram_range = (1,2))\n",
    "X_train_vect = vectorizer.fit_transform(X_train['text_cleaned_no_SW'].values)\n",
    "X_test_vect = vectorizer.transform(X_test['text_cleaned_no_SW'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_model = MultinomialNB()\n",
    "NB_model.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score = 0.6653\n"
     ]
    }
   ],
   "source": [
    "NB_fitted_model, score = train_model(X_train_vect, y_train, NB_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NB Model - Cleaning Steps</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Baseline NB</td>\n",
       "      <td>0.6753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Punctuation Removed</td>\n",
       "      <td>0.6708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Punct. &amp; Digits Removed</td>\n",
       "      <td>0.6716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Punct, Digits &amp; SW Removed - manually</td>\n",
       "      <td>0.6614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Punct, Digits, SW &amp; Links Removed</td>\n",
       "      <td>0.6675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Punct, Digits, SW &amp; Links Removed - Snowball</td>\n",
       "      <td>0.6635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Punct, Digits, SW &amp; Links Removed - Porter</td>\n",
       "      <td>0.6648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Punct, Digits, SW &amp; Links Removed - Lemmatized</td>\n",
       "      <td>0.6673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Punct, Digits, Links, SW Removed - Bigrams</td>\n",
       "      <td>0.6653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        NB Model - Cleaning Steps  F1 Score\n",
       "0                                     Baseline NB    0.6753\n",
       "1                             Punctuation Removed    0.6708\n",
       "2                         Punct. & Digits Removed    0.6716\n",
       "3           Punct, Digits & SW Removed - manually    0.6614\n",
       "4               Punct, Digits, SW & Links Removed    0.6675\n",
       "5    Punct, Digits, SW & Links Removed - Snowball    0.6635\n",
       "6      Punct, Digits, SW & Links Removed - Porter    0.6648\n",
       "7  Punct, Digits, SW & Links Removed - Lemmatized    0.6673\n",
       "8      Punct, Digits, Links, SW Removed - Bigrams    0.6653"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.loc[len(results_df)] = ['Punct, Digits, Links, SW Removed - Bigrams', round(score,4)]\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again,  we see that bigrams has slightly lowered the performance, however this step proved to be helpful when applied to the test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After multiple rounds of trial and error, I achieved my highest score on Kaggle by applying the following data cleaning steps:\n",
    "1. Remove punctuation\n",
    "2. Remove digits\n",
    "3. Remove stopwords\n",
    "4. Remove links\n",
    "5. Use bigrams\n",
    "\n",
    "To summarize, one thing that was important to keep in mind during the assignment is that the results in the train set can be misleading, therefore it is important to make submissions to Kaggle to get an idea of the \"right path\" for this dataset. Another important lesson is that when dealing with unordinary textual data, such as tweets, additional cleaning steps beyond basic cleaning is required for the model to handle the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Username and score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Username: nmatta72\n",
    "- Score: 0.80674"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT - Attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've tried implementing a BERT model, however this proved to be quite challenging in terms of installations and inconsistencies with my version of Python. Below is my code to initialize a BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install tensorflow\n",
    "# pip install --upgrade tensorflow-hub\n",
    "# conda install pytorch-cpu torchvision-cpu -c pytorch\n",
    "# pip install pytorch_pretrained_bert\n",
    "# pip install keras\n",
    "# conda install -c pytorch torchvision cudatoolkit=10.1 pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.layers import Dense, Input\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "# import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# import numpy as np\n",
    "# import random as rn\n",
    "# import torch\n",
    "# from pytorch_pretrained_bert import BertModel\n",
    "# from torch import nn\n",
    "# from pytorch_pretrained_bert import BertTokenizer\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "# from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "# from torch.optim import Adam\n",
    "# from torch.nn.utils import clip_grad_norm_\n",
    "# from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "# train_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:511], X_train['text_cleaned']))\n",
    "# test_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:511], X_test['text_cleaned']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_tokens_ids = list(map(tokenizer.convert_tokens_to_ids, train_tokens))\n",
    "# test_tokens_ids = list(map(tokenizer.convert_tokens_to_ids, test_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_tokens_ids = pad_sequences(train_tokens_ids, maxlen=512, truncating=\"post\", padding=\"post\", dtype=\"int\")\n",
    "# test_tokens_ids = pad_sequences(test_tokens_ids, maxlen=512, truncating=\"post\", padding=\"post\", dtype=\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_masks = [[float(i > 0) for i in ii] for ii in train_tokens_ids]\n",
    "# test_masks = [[float(i > 0) for i in ii] for ii in test_tokens_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class BertBinaryClassifier(nn.Module):\n",
    "#     def __init__(self, dropout=0.1):\n",
    "#         super(BertBinaryClassifier, self).__init__()\n",
    "\n",
    "#         self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "#         self.dropout = nn.Dropout(dropout)\n",
    "#         self.linear = nn.Linear(768, 1)\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "#     def forward(self, tokens, masks=None):\n",
    "#         _, pooled_output = self.bert(tokens, attention_mask=masks, output_all_encoded_layers=False)\n",
    "#         dropout_output = self.dropout(pooled_output)\n",
    "#         linear_output = self.linear(dropout_output)\n",
    "#         proba = self.sigmoid(linear_output)\n",
    "#         return proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert_clf = BertBinaryClassifier()\n",
    "# bert_clf = bert_clf.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_tokens_tensor = torch.tensor(train_tokens_ids)\n",
    "# train_y_tensor = torch.tensor(y_train.reshape(-1, 1)).float()\n",
    "\n",
    "# test_tokens_tensor = torch.tensor(test_tokens_ids)\n",
    "# # test_y_tensor = torch.tensor(test_y.reshape(-1, 1)).float()\n",
    "\n",
    "# train_masks_tensor = torch.tensor(train_masks)\n",
    "# test_masks_tensor = torch.tensor(test_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = TensorDataset(train_tokens_tensor, train_masks_tensor, train_y_tensor)\n",
    "# train_sampler = RandomSampler(train_dataset)\n",
    "# train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_optimizer = list(bert_clf.sigmoid.named_parameters()) \n",
    "# optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = Adam(bert_clf.parameters(), lr=3e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch_num in range(10):\n",
    "#     bert_clf.train()\n",
    "#     train_loss = 0\n",
    "#     for step_num, batch_data in enumerate(train_dataloader):\n",
    "#         token_ids, masks, labels = tuple(t.to(device) for t in batch_data)\n",
    "#         print(str(torch.cuda.memory_allocated(device)/1000000 ) + 'M')\n",
    "#         logits = bert_clf(token_ids, masks)\n",
    "        \n",
    "#         loss_func = nn.BCELoss()\n",
    "\n",
    "#         batch_loss = loss_func(logits, labels)\n",
    "#         train_loss += batch_loss.item()\n",
    "        \n",
    "        \n",
    "#         bert_clf.zero_grad()\n",
    "#         batch_loss.backward()\n",
    "        \n",
    "\n",
    "#         clip_grad_norm_(parameters=bert_clf.parameters(), max_norm=1.0)\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         clear_output(wait=True)\n",
    "#         print('Epoch: ', epoch_num + 1)\n",
    "#         print(\"\\r\" + \"{0}/{1} loss: {2} \".format(step_num, len(train_data) / BATCH_SIZE, train_loss / (step_num + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert_clf = BertBinaryClassifier()\n",
    "# optimizer = Adam(bert_clf.parameters(), lr=3e-6)\n",
    "# bert_clf.train()\n",
    "# for epoch_num in range(10):\n",
    "#     for step_num, batch_data in enumerate(train_dataloader):\n",
    "#         token_ids, labels = tuple(t for t in batch_data)\n",
    "#         probas = bert_clf(token_ids)\n",
    "#         loss_func = nn.BCELoss()\n",
    "#         batch_loss = loss_func(probas, labels)\n",
    "#         bert_clf.zero_grad()\n",
    "#         batch_loss.backward()\n",
    "#         optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_model(bert_layer, max_len=512):\n",
    "#     input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "#     input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
    "#     segment_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n",
    "\n",
    "#     _, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
    "#     clf_output = sequence_output[:, 0, :]\n",
    "#     out = Dense(1, activation='sigmoid')(clf_output)\n",
    "    \n",
    "#     model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n",
    "#     model.compile(Adam(lr=2e-6), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# module_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/1\"\n",
    "# bert_layer = hub.KerasLayer(module_url, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "# do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "# tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
